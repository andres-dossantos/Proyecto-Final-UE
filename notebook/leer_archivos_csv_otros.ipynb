{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cargar el diccionario desde el archivo JSON\n",
    "#with open('Project_countries.json', 'r') as json_file:\n",
    "# country_region_continent = json.load(json_file)\n",
    "\n",
    "# Leer el archivo JSON con la codificación correcta\n",
    "with open('Project_countries.json', 'r', encoding='utf-8') as file:\n",
    "    Project_countries = json.load(file)\n",
    "\n",
    "# Crear un diccionario inverso para los nombres alternativos\n",
    "alternate_names_to_official = {}\n",
    "for country, info in Project_countries.items():\n",
    "    for alt_name in info.get('AlternateNames', []):\n",
    "        alternate_names_to_official[alt_name] = country\n",
    "\n",
    "# Definir la ruta de la carpeta\n",
    "folder_path = 'Datos/Consolidado 2/Archivos'\n",
    "\n",
    "# Obtener una lista de todos los archivos CSV en la carpeta\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Inicializar un DataFrame vacío para almacenar todos los datos transpuestos\n",
    "all_transposed_data = pd.DataFrame()\n",
    "\n",
    "# Leer y procesar cada archivo CSV\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    try:\n",
    "        # Leer el archivo CSV con el delimitador adecuado\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Encontrar el índice de la fila \"Country Name\"\n",
    "        start_index = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.startswith('\"Country Name\"'):\n",
    "                start_index = i\n",
    "                break\n",
    "        \n",
    "        if start_index is None:\n",
    "            print(f'No se encontró la fila \"Country Name\" en el archivo {csv_file}')\n",
    "            continue\n",
    "                \n",
    "        # Leer el archivo CSV desde la fila \"Country Name\"\n",
    "        data = pd.read_csv(file_path, encoding='utf-8', delimiter=',', quotechar='\"', on_bad_lines='skip', skiprows=start_index)\n",
    "        \n",
    "        # Reemplazar nombres alternativos por nombres oficiales\n",
    "        data['Country Name'] = data['Country Name'].apply(lambda x: alternate_names_to_official.get(x, x))  \n",
    "        \n",
    "        # Validar que todos los países de la primera columna se encuentren en el archivo JSON\n",
    "        valid_countries = data['Country Name'].isin(Project_countries.keys())\n",
    "        data_cleaned = data[valid_countries]\n",
    "        \n",
    "        # Eliminar las filas vacías del DataFrame original\n",
    "        filas_vacias = data_cleaned[data_cleaned.iloc[:, 0].isnull() | (data_cleaned.iloc[:, 0] == '')]\n",
    "        data_cleaned = data_cleaned.drop(filas_vacias.index)\n",
    "        \n",
    "        # Eliminar columnas de años que no se necesitan\n",
    "        columns_to_keep = list(data_cleaned.columns[:4]) + list(data_cleaned.columns[-10:])\n",
    "        data_cleaned = data_cleaned[columns_to_keep]\n",
    "\n",
    "        # Crear columnas adicionales para Región y Continente\n",
    "        data_cleaned['Region'] = data_cleaned['Country Name'].apply(lambda x: country_region_continent.get(x, {}).get('Region', 'Región Desconocida'))\n",
    "        data_cleaned['Continent'] = data_cleaned['Country Name'].apply(lambda x: country_region_continent.get(x, {}).get('Continent', 'Continente Desconocido'))\n",
    "        \n",
    "        # Crear una lista para almacenar las filas transpuestas\n",
    "        transposed_data = []\n",
    "        \n",
    "        # Se define desde que columna lee los años\n",
    "        years = data_cleaned.columns[4:]\n",
    "\n",
    "        # Iterar sobre cada fila del DataFrame original\n",
    "        for index, row in data_cleaned.iterrows():\n",
    "            country_name = row['Country Name']\n",
    "            country_code = row['Country Code']\n",
    "            indicator_name = row['Indicator Name']\n",
    "            indicator_code = row['Indicator Code']\n",
    "            region = row['Region']\n",
    "            continent = row['Continent']\n",
    "    \n",
    "            # Iterar sobre las columnas de años\n",
    "            for year in years[:-2]:  # Excluir 'Unnamed: 68' y 'Most_Recent_Value'\n",
    "                value = row[year]\n",
    "                if not pd.isna(value):\n",
    "                    transposed_data.append([country_name, country_code, indicator_name, indicator_code, year, value, region, continent])\n",
    "\n",
    "        # Crear un nuevo DataFrame con los datos transpuestos\n",
    "        transposed_df = pd.DataFrame(transposed_data, columns=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code', 'Year', 'Value', 'Region', 'Continent'])\n",
    "\n",
    "        # Concatenar los datos transpuestos al DataFrame principal\n",
    "        all_transposed_data = pd.concat([all_transposed_data, transposed_df], ignore_index=True)\n",
    "        \n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f'Error al procesar el archivo {csv_file}: {e}')\n",
    "\n",
    "# Ordenar el DataFrame combinado por el nombre de la columna \"Country Name\"\n",
    "all_transposed_data.sort_values(by=['Country Name', 'Indicator Name'], inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame combinado ordenado\n",
    "print(all_transposed_data.head())\n",
    "\n",
    "# Guardar el DataFrame combinado en un archivo CSV\n",
    "\n",
    "# Definir la ruta de la carpeta\n",
    "New_folder_path = 'Datos'\n",
    "output_file_path = os.path.join(New_folder_path, 'transposed_data.csv')\n",
    "all_transposed_data.to_csv(output_file_path, index=False)\n",
    "print(f'El archivo CSV combinado se ha guardado en: {output_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versión 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Definir la ruta de la carpeta\n",
    "folder_path = 'Datos/Consolidado 2/Archivos'\n",
    "\n",
    "# Obtener una lista de todos los archivos CSV en la carpeta\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Inicializar un DataFrame vacío para almacenar todos los datos transpuestos\n",
    "all_transposed_data = pd.DataFrame()\n",
    "\n",
    "# Leer y procesar cada archivo CSV\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    try:\n",
    "        # Leer el archivo CSV con el delimitador adecuado\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Encontrar el índice de la fila \"Country Name\"\n",
    "        start_index = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.startswith('\"Country Name\"'):\n",
    "                start_index = i\n",
    "                break\n",
    "        \n",
    "        if start_index is None:\n",
    "            print(f'No se encontró la fila \"Country Name\" en el archivo {csv_file}')\n",
    "            continue\n",
    "                \n",
    "        # Leer el archivo CSV desde la fila \"Country Name\"\n",
    "        data = pd.read_csv(file_path, encoding='utf-8', delimiter=',', quotechar='\"', on_bad_lines='skip', skiprows=start_index)\n",
    "        \n",
    "        data\n",
    "        \n",
    "        \n",
    "        \n",
    "        filas_vacias = data[data.iloc[:, 0].isnull() | (data.iloc[:, 0] == '')]\n",
    "        \n",
    "        #print(f'filas vacias:')\n",
    "        #print (filas_vacias)\n",
    "        \n",
    "        # Eliminar las filas vacías del DataFrame original\n",
    "        data_cleaned = data.drop(filas_vacias.index)\n",
    "        \n",
    "        \n",
    "        # Eliminar las filas vacías del DataFrame original\n",
    "        #data_cleaned = data.dropna(subset=[data.columns[0]])\n",
    "        \n",
    "        # Se define desde que columna lee los años\n",
    "        years = data_cleaned.columns[4:]\n",
    "\n",
    "        # Crear una lista para almacenar las filas transpuestas\n",
    "        transposed_data = []\n",
    "\n",
    "        # Iterar sobre cada fila del DataFrame original\n",
    "        for index, row in data_cleaned.iterrows():\n",
    "            country_name = row['Country Name']\n",
    "            country_code = row['Country Code']\n",
    "            indicator_name = row['Indicator Name']\n",
    "            indicator_code = row['Indicator Code']\n",
    "    \n",
    "            # Iterar sobre las columnas de años\n",
    "            for year in years[:-2]:  # Excluir 'Unnamed: 68' y 'Most_Recent_Value'\n",
    "                value = row[year]\n",
    "                if not pd.isna(value):\n",
    "                    transposed_data.append([country_name, country_code, indicator_name, indicator_code, year, value])\n",
    "\n",
    "        # Crear un nuevo DataFrame con los datos transpuestos\n",
    "        transposed_df = pd.DataFrame(transposed_data, columns=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code', 'Year', 'Value'])\n",
    "\n",
    "        # Concatenar los datos transpuestos al DataFrame principal\n",
    "        all_transposed_data = pd.concat([all_transposed_data, transposed_df], ignore_index=True)\n",
    "        \n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f'Error al procesar el archivo {csv_file}: {e}')\n",
    "\n",
    "# Ordenar el DataFrame combinado por el nombre de la columna \"Country Name\"\n",
    "all_transposed_data.sort_values(by=['Country Name', 'Indicator Name'], inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame combinado ordenado\n",
    "print(all_transposed_data.head())\n",
    "\n",
    "# Guardar el DataFrame combinado en un archivo CSV\n",
    "output_file_path = os.path.join(folder_path, 'transposed_data.csv')\n",
    "all_transposed_data.to_csv(output_file_path, index=False)\n",
    "print(f'El archivo CSV combinado se ha guardado en: {output_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versiòn 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontró la fila \"Country Name\" en el archivo transposed_data.csv\n",
      "          Country Name Country Code  \\\n",
      "1288   Ingreso mediano          MIC   \n",
      "1289   Ingreso mediano          MIC   \n",
      "1290   Ingreso mediano          MIC   \n",
      "1291   Ingreso mediano          MIC   \n",
      "1292   Ingreso mediano          MIC   \n",
      "\n",
      "                                         Indicator Name  Indicator Code  Year  \\\n",
      "1288  Agricultura, silvicultura y pesca, valor agreg...  NV.AGR.TOTL.ZS  2015   \n",
      "1289  Agricultura, silvicultura y pesca, valor agreg...  NV.AGR.TOTL.ZS  2016   \n",
      "1290  Agricultura, silvicultura y pesca, valor agreg...  NV.AGR.TOTL.ZS  2017   \n",
      "1291  Agricultura, silvicultura y pesca, valor agreg...  NV.AGR.TOTL.ZS  2018   \n",
      "1292  Agricultura, silvicultura y pesca, valor agreg...  NV.AGR.TOTL.ZS  2019   \n",
      "\n",
      "         Value              Region               Continent  \n",
      "1288  9.288169  Región Desconocida  Continente Desconocido  \n",
      "1289  9.274337  Región Desconocida  Continente Desconocido  \n",
      "1290  8.866479  Región Desconocida  Continente Desconocido  \n",
      "1291  8.527287  Región Desconocida  Continente Desconocido  \n",
      "1292  8.697503  Región Desconocida  Continente Desconocido  \n",
      "El archivo CSV combinado se ha guardado en: Datos/Consolidado 2/Archivos\\transposed_data.csv\n",
      "El archivo CSV con los valores únicos se ha guardado como unique_countries.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cargar el diccionario desde el archivo JSON\n",
    "with open('country_region_continent.json', 'r') as json_file:\n",
    "    country_region_continent = json.load(json_file)\n",
    "\n",
    "# Definir la ruta de la carpeta\n",
    "folder_path = 'Datos/Consolidado 2/Archivos'\n",
    "\n",
    "# Obtener una lista de todos los archivos CSV en la carpeta\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Inicializar un DataFrame vacío para almacenar todos los datos transpuestos\n",
    "all_transposed_data = pd.DataFrame()\n",
    "\n",
    "# Leer y procesar cada archivo CSV\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    try:\n",
    "        # Leer el archivo CSV con el delimitador adecuado\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Encontrar el índice de la fila \"Country Name\"\n",
    "        start_index = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.startswith('\"Country Name\"'):\n",
    "                start_index = i\n",
    "                break\n",
    "        \n",
    "        if start_index is None:\n",
    "            print(f'No se encontró la fila \"Country Name\" en el archivo {csv_file}')\n",
    "            continue\n",
    "                \n",
    "        # Leer el archivo CSV desde la fila \"Country Name\"\n",
    "        data = pd.read_csv(file_path, encoding='utf-8', delimiter=',', quotechar='\"', on_bad_lines='skip', skiprows=start_index)\n",
    "               \n",
    "        # Eliminar las filas vacías del DataFrame original\n",
    "        filas_vacias = data[data.iloc[:, 0].isnull() | (data.iloc[:, 0] == '')]\n",
    "        data_cleaned = data.drop(filas_vacias.index)\n",
    "        \n",
    "        # Eliminar columnas de años que no se necesitan\n",
    "        columns_to_keep = list(data_cleaned.columns[:4]) + list(data_cleaned.columns[-10:])\n",
    "        data_cleaned = data_cleaned[columns_to_keep]\n",
    "\n",
    "        # Crear columnas adicionales para Región y Continente\n",
    "        data_cleaned['Region'] = data_cleaned['Country Name'].apply(lambda x: country_region_continent.get(x, {}).get('Region', 'Región Desconocida'))\n",
    "        data_cleaned['Continent'] = data_cleaned['Country Name'].apply(lambda x: country_region_continent.get(x, {}).get('Continent', 'Continente Desconocido'))\n",
    "        \n",
    "        # Crear una lista para almacenar las filas transpuestas\n",
    "        transposed_data = []\n",
    "        \n",
    "        # Se define desde que columna lee los años\n",
    "        years = data_cleaned.columns[4:]\n",
    "\n",
    "        # Iterar sobre cada fila del DataFrame original\n",
    "        for index, row in data_cleaned.iterrows():\n",
    "            country_name = row['Country Name']\n",
    "            country_code = row['Country Code']\n",
    "            indicator_name = row['Indicator Name']\n",
    "            indicator_code = row['Indicator Code']\n",
    "            region = row['Region']\n",
    "            continent = row['Continent']\n",
    "    \n",
    "            # Iterar sobre las columnas de años\n",
    "            for year in years[:-2]:  # Excluir 'Unnamed: 68' y 'Most_Recent_Value'\n",
    "                value = row[year]\n",
    "                if not pd.isna(value):\n",
    "                    transposed_data.append([country_name, country_code, indicator_name, indicator_code, year, value, region, continent])\n",
    "\n",
    "        # Crear un nuevo DataFrame con los datos transpuestos\n",
    "        transposed_df = pd.DataFrame(transposed_data, columns=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code', 'Year', 'Value', 'Region', 'Continent'])\n",
    "\n",
    "        # Concatenar los datos transpuestos al DataFrame principal\n",
    "        all_transposed_data = pd.concat([all_transposed_data, transposed_df], ignore_index=True)\n",
    "        \n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f'Error al procesar el archivo {csv_file}: {e}')\n",
    "\n",
    "# Ordenar el DataFrame combinado por el nombre de la columna \"Country Name\"\n",
    "all_transposed_data.sort_values(by=['Country Name', 'Indicator Name'], inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame combinado ordenado\n",
    "print(all_transposed_data.head())\n",
    "\n",
    "# Guardar el DataFrame combinado en un archivo CSV\n",
    "output_file_path = os.path.join(folder_path, 'transposed_data.csv')\n",
    "all_transposed_data.to_csv(output_file_path, index=False)\n",
    "print(f'El archivo CSV combinado se ha guardado en: {output_file_path}')\n",
    "\n",
    "\n",
    "unique_countries = all_transposed_data[['Country Name', 'Country Code', 'Region', 'Continent']].drop_duplicates()\n",
    "\n",
    "# Guardar los valores únicos en un archivo CSV\n",
    "unique_countries.to_csv('unique_countries.csv', index=False)\n",
    "print('El archivo CSV con los valores únicos se ha guardado como unique_countries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los valores únicos de la columna 'Country Name'\n",
    "unique_countries = all_transposed_data[['Country Name', 'Country Code', 'Region', 'Continent']].drop_duplicates()\n",
    "\n",
    "# Guardar los valores únicos en un archivo CSV\n",
    "unique_countries.to_csv('unique_countries.csv', index=False)\n",
    "print('El archivo CSV con los valores únicos se ha guardado como unique_countries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versión 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontró la fila \"Country Name\" en el archivo transposed_data.csv\n",
      "  Country Name Country Code  \\\n",
      "5   Afganistán          AFG   \n",
      "6   Afganistán          AFG   \n",
      "7   Afganistán          AFG   \n",
      "8   Afganistán          AFG   \n",
      "9   Afganistán          AFG   \n",
      "\n",
      "                                      Indicator Name  Indicator Code  Year  \\\n",
      "5  Agricultura, silvicultura y pesca, valor agreg...  NV.AGR.TOTL.ZS  2015   \n",
      "6  Agricultura, silvicultura y pesca, valor agreg...  NV.AGR.TOTL.ZS  2016   \n",
      "7  Agricultura, silvicultura y pesca, valor agreg...  NV.AGR.TOTL.ZS  2017   \n",
      "8  Agricultura, silvicultura y pesca, valor agreg...  NV.AGR.TOTL.ZS  2018   \n",
      "9  Agricultura, silvicultura y pesca, valor agreg...  NV.AGR.TOTL.ZS  2019   \n",
      "\n",
      "       Value              Region               Continent  \n",
      "5  20.634323  Región Desconocida  Continente Desconocido  \n",
      "6  25.740314  Región Desconocida  Continente Desconocido  \n",
      "7  26.420199  Región Desconocida  Continente Desconocido  \n",
      "8  22.042897  Región Desconocida  Continente Desconocido  \n",
      "9  25.773971  Región Desconocida  Continente Desconocido  \n",
      "El archivo CSV combinado se ha guardado en: Datos\\transposed_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cargar el diccionario desde el archivo JSON\n",
    "#with open('Project_countries.json', 'r') as json_file:\n",
    "# country_region_continent = json.load(json_file)\n",
    "\n",
    "# Leer el archivo JSON con la codificación correcta\n",
    "with open('Project_countries.json', 'r', encoding='utf-8') as file:\n",
    "    Project_countries = json.load(file)\n",
    "\n",
    "# Crear un diccionario inverso para los nombres alternativos\n",
    "alternate_names_to_official = {}\n",
    "for country, info in Project_countries.items():\n",
    "    for alt_name in info.get('AlternateNames', []):\n",
    "        alternate_names_to_official[alt_name] = country\n",
    "\n",
    "# Definir la ruta de la carpeta\n",
    "folder_path = 'Datos/Consolidado 2/Archivos'\n",
    "\n",
    "# Obtener una lista de todos los archivos CSV en la carpeta\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Inicializar un DataFrame vacío para almacenar todos los datos transpuestos\n",
    "all_transposed_data = pd.DataFrame()\n",
    "\n",
    "# Leer y procesar cada archivo CSV\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    try:\n",
    "        # Leer el archivo CSV con el delimitador adecuado\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Encontrar el índice de la fila \"Country Name\"\n",
    "        start_index = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.startswith('\"Country Name\"'):\n",
    "                start_index = i\n",
    "                break\n",
    "        \n",
    "        if start_index is None:\n",
    "            print(f'No se encontró la fila \"Country Name\" en el archivo {csv_file}')\n",
    "            continue\n",
    "                \n",
    "        # Leer el archivo CSV desde la fila \"Country Name\"\n",
    "        data = pd.read_csv(file_path, encoding='utf-8', delimiter=',', quotechar='\"', on_bad_lines='skip', skiprows=start_index)\n",
    "        \n",
    "        # Reemplazar nombres alternativos por nombres oficiales\n",
    "        data['Country Name'] = data['Country Name'].apply(lambda x: alternate_names_to_official.get(x, x))  \n",
    "        \n",
    "        # Validar que todos los países de la primera columna se encuentren en el archivo JSON\n",
    "        valid_countries = data['Country Name'].isin(Project_countries.keys())\n",
    "        data_cleaned = data[valid_countries]\n",
    "        \n",
    "        # Eliminar las filas vacías del DataFrame original\n",
    "        filas_vacias = data_cleaned[data_cleaned.iloc[:, 0].isnull() | (data_cleaned.iloc[:, 0] == '')]\n",
    "        data_cleaned = data_cleaned.drop(filas_vacias.index)\n",
    "        \n",
    "        # Eliminar columnas de años que no se necesitan\n",
    "        columns_to_keep = list(data_cleaned.columns[:4]) + list(data_cleaned.columns[-10:])\n",
    "        data_cleaned = data_cleaned[columns_to_keep]\n",
    "\n",
    "        # Crear columnas adicionales para Región y Continente\n",
    "        data_cleaned['Region'] = data_cleaned['Country Name'].apply(lambda x: country_region_continent.get(x, {}).get('Region', 'Región Desconocida'))\n",
    "        data_cleaned['Continent'] = data_cleaned['Country Name'].apply(lambda x: country_region_continent.get(x, {}).get('Continent', 'Continente Desconocido'))\n",
    "        \n",
    "        # Crear una lista para almacenar las filas transpuestas\n",
    "        transposed_data = []\n",
    "        \n",
    "        # Se define desde que columna lee los años\n",
    "        years = data_cleaned.columns[4:]\n",
    "\n",
    "        # Iterar sobre cada fila del DataFrame original\n",
    "        for index, row in data_cleaned.iterrows():\n",
    "            country_name = row['Country Name']\n",
    "            country_code = row['Country Code']\n",
    "            indicator_name = row['Indicator Name']\n",
    "            indicator_code = row['Indicator Code']\n",
    "            region = row['Region']\n",
    "            continent = row['Continent']\n",
    "    \n",
    "            # Iterar sobre las columnas de años\n",
    "            for year in years[:-2]:  # Excluir 'Unnamed: 68' y 'Most_Recent_Value'\n",
    "                value = row[year]\n",
    "                if not pd.isna(value):\n",
    "                    transposed_data.append([country_name, country_code, indicator_name, indicator_code, year, value, region, continent])\n",
    "\n",
    "        # Crear un nuevo DataFrame con los datos transpuestos\n",
    "        transposed_df = pd.DataFrame(transposed_data, columns=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code', 'Year', 'Value', 'Region', 'Continent'])\n",
    "\n",
    "        # Concatenar los datos transpuestos al DataFrame principal\n",
    "        all_transposed_data = pd.concat([all_transposed_data, transposed_df], ignore_index=True)\n",
    "        \n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f'Error al procesar el archivo {csv_file}: {e}')\n",
    "\n",
    "# Ordenar el DataFrame combinado por el nombre de la columna \"Country Name\"\n",
    "all_transposed_data.sort_values(by=['Country Name', 'Indicator Name'], inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame combinado ordenado\n",
    "print(all_transposed_data.head())\n",
    "\n",
    "# Guardar el DataFrame combinado en un archivo CSV\n",
    "\n",
    "# Definir la ruta de la carpeta\n",
    "New_folder_path = 'Datos'\n",
    "output_file_path = os.path.join(New_folder_path, 'transposed_data.csv')\n",
    "all_transposed_data.to_csv(output_file_path, index=False)\n",
    "print(f'El archivo CSV combinado se ha guardado en: {output_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 5 leer archivos happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidación completa. Los datos consolidados se han guardado en consolidado_happiness.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define la ruta de la carpeta y el archivo JSON\n",
    "folder_path = 'Datos/Happiness'\n",
    "#json_path = 'Project_countries.json'\n",
    "\n",
    "# Define los mapeos de columnas\n",
    "column_mappings = {\n",
    "    'Country': ['Country', 'Country or region','Country name'],\n",
    "    'Rank': ['Happiness Rank', 'Overall rank', 'Happiness.Rank','Rank'],\n",
    "    'Score': ['Happiness Score', 'Score', 'Happiness.Score','Ladder score','Happiness score'],\n",
    "    'GDP per capita': ['Economy (GDP per Capita)', 'Economy..GDP.per.Capita.', 'GDP per capita','Logged GDP per capita','Explained by: GDP per capita'],\n",
    "    'Family': ['Family', 'Social support','Explained by: Social support'],\n",
    "    'Health (Life Expectancy)': ['Health (Life Expectancy)', 'Health..Life.Expectancy.', 'Healthy life expectancy','Explained by: Healthy life expectancy'],\n",
    "    'Freedom': ['Freedom', 'Freedom to make life choices','Explained by: Freedom to make life choices'],\n",
    "    'Perceptions of corruption': ['Trust (Government Corruption)', 'Trust..Government.Corruption.', 'Perceptions of corruption','Explained by: Perceptions of corruption'],\n",
    "    'Generosity': ['Generosity','Explained by: Generosity']\n",
    "}\n",
    "\n",
    "# Crear un diccionario inverso para los nombres alternativos\n",
    "alternate_names_to_official = {}\n",
    "for country, info in Project_countries.items():\n",
    "    for alt_name in info.get('AlternateNames', []):\n",
    "        alternate_names_to_official[alt_name] = country\n",
    "\n",
    "# Función para estandarizar los nombres de las columnas\n",
    "def standardize_columns(df):\n",
    "    standardized_columns = {}\n",
    "    for standard_col, possible_cols in column_mappings.items():\n",
    "        for col in possible_cols:\n",
    "            if col in df.columns:\n",
    "                standardized_columns[col] = standard_col\n",
    "                break\n",
    "    return df.rename(columns=standardized_columns)\n",
    "\n",
    "# Leer el archivo JSON con la codificación correcta\n",
    "with open('Project_countries.json', 'r', encoding='utf-8') as file:\n",
    "    project_countries = json.load(file)\n",
    "\n",
    "# Lista para almacenar los dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterar sobre los archivos en la carpeta\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extraer el año del nombre del archivo\n",
    "        year = int(''.join(filter(str.isdigit, filename)))\n",
    "        \n",
    "        # Leer el archivo CSV\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Estandarizar las columnas\n",
    "        df = standardize_columns(df)\n",
    "        \n",
    "        # Asignar Rank si no existe en el archivo\n",
    "        if 'Rank' not in df.columns:\n",
    "            df['Rank'] = range(1, len(df) + 1)\n",
    "        \n",
    "        # Reemplazar nombres alternativos por nombres oficiales\n",
    "        df['Country'] = df['Country'].apply(lambda x: alternate_names_to_official.get(x, x))\n",
    "        \n",
    "        # Filtrar las filas basadas en el archivo JSON\n",
    "        df = df[df['Country'].isin(project_countries)]\n",
    "        \n",
    "        # Filtrar las columnas relevantes y agregar la columna de año\n",
    "        df = df[['Country', 'Rank', 'Score', 'GDP per capita', 'Family', \n",
    "                 'Health (Life Expectancy)', 'Freedom', \n",
    "                 'Perceptions of corruption', 'Generosity']]\n",
    "        df['Year'] = year\n",
    "        \n",
    "        # Formatear los datos numéricos para que solo tengan 3 dígitos\n",
    "        numeric_columns = ['Rank', 'Score', 'GDP per capita', 'Family', \n",
    "                           'Health (Life Expectancy)', 'Freedom', \n",
    "                           'Perceptions of corruption', 'Generosity']\n",
    "        df[numeric_columns] = df[numeric_columns].applymap(lambda x: round(x, 3) if isinstance(x, (int, float)) else x)\n",
    "        \n",
    "        \n",
    "        # Formatear los datos numéricos para que solo tengan 3 dígitos\n",
    "        #numeric_columns = ['Rank', 'Score', 'GDP per capita', 'Family', \n",
    "        #                   'Health (Life Expectancy)', 'Freedom', \n",
    "        #                   'Perceptions of corruption', 'Generosity']\n",
    "        #df[numeric_columns] = df[numeric_columns].apply(lambda x: round(x, 3) if isinstance(x, (int, float)) else x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Agregar el dataframe a la lista\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenar todos los dataframes\n",
    "consolidated_df = pd.concat(dataframes)\n",
    "\n",
    "# Ordenar el DataFrame combinado por el nombre de la columna \"Country Name\"\n",
    "consolidated_df.sort_values(by=['Country'], inplace=True)\n",
    "\n",
    "# Guardar el dataframe consolidado en un nuevo archivo CSV\n",
    "consolidated_df.to_csv('consolidado_happiness.csv', index=False)\n",
    "\n",
    "print(\"Consolidación completa. Los datos consolidados se han guardado en consolidado_happiness.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidación completa. Los datos consolidados se han guardado en consolidado_happiness_v2.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define la ruta de la carpeta y el archivo JSON\n",
    "folder_path = 'Datos/Happiness'\n",
    "json_path = 'Project_countries.json'\n",
    "\n",
    "# Define los mapeos de columnas\n",
    "column_mappings = {\n",
    "    'Country': ['Country', 'Country or region','Country name'],\n",
    "    'Rank': ['Happiness Rank', 'Overall rank', 'Happiness.Rank','Rank'],\n",
    "    'Score': ['Happiness Score', 'Score', 'Happiness.Score','Ladder score','Happiness score'],\n",
    "    'GDP per capita': ['Economy (GDP per Capita)', 'Economy..GDP.per.Capita.', 'GDP per capita','Logged GDP per capita','Explained by: GDP per capita'],\n",
    "    'Family': ['Family', 'Social support','Explained by: Social support'],\n",
    "    'Health (Life Expectancy)': ['Health (Life Expectancy)', 'Health..Life.Expectancy.', 'Healthy life expectancy','Explained by: Healthy life expectancy'],\n",
    "    'Freedom': ['Freedom', 'Freedom to make life choices','Explained by: Freedom to make life choices'],\n",
    "    'Perceptions of corruption': ['Trust (Government Corruption)', 'Trust..Government.Corruption.', 'Perceptions of corruption','Explained by: Perceptions of corruption'],\n",
    "    'Generosity': ['Generosity','Explained by: Generosity']\n",
    "}\n",
    "\n",
    "# Crear un diccionario inverso para los nombres alternativos\n",
    "alternate_names_to_official = {}\n",
    "with open(json_path, 'r', encoding='utf-8') as file:\n",
    "    project_countries = json.load(file)\n",
    "    for country, info in project_countries.items():\n",
    "        for alt_name in info.get('AlternateNames', []):\n",
    "            alternate_names_to_official[alt_name] = country\n",
    "\n",
    "# Función para estandarizar los nombres de las columnas y eliminar las no deseadas\n",
    "def standardize_columns(df):\n",
    "    standardized_columns = {}\n",
    "    for standard_col, possible_cols in column_mappings.items():\n",
    "        for col in possible_cols:\n",
    "            if col in df.columns:\n",
    "                standardized_columns[col] = standard_col\n",
    "                break\n",
    "    df = df.rename(columns=standardized_columns)\n",
    "    # Eliminar columnas que no están en los mapeos\n",
    "    columns_to_keep = list(standardized_columns.values())\n",
    "    df = df[columns_to_keep]\n",
    "    return df\n",
    "\n",
    "# Lista para almacenar los dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterar sobre los archivos en la carpeta\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extraer el año del nombre del archivo\n",
    "        year = int(''.join(filter(str.isdigit, filename)))\n",
    "        \n",
    "        # Leer el archivo CSV\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Eliminar filas vacías\n",
    "        df.dropna(how='all', inplace=True)\n",
    "        \n",
    "        # Estandarizar las columnas y eliminar las no deseadas\n",
    "        df = standardize_columns(df)\n",
    "        \n",
    "        # Asignar Rank si no existe en el archivo\n",
    "        if 'Rank' not in df.columns:\n",
    "            df['Rank'] = range(1, len(df) + 1)\n",
    "        \n",
    "        # Asegurarse de que los valores de 'Country' sean cadenas y manejar valores nulos\n",
    "        df['Country'] = df['Country'].astype(str).fillna('')\n",
    "        \n",
    "        # Reemplazar nombres alternativos por nombres oficiales\n",
    "        df['Country'] = df['Country'].apply(lambda x: alternate_names_to_official.get(x, x))\n",
    "        \n",
    "        # Filtrar las filas basadas en el archivo JSON\n",
    "        df = df[df['Country'].isin(project_countries)]\n",
    "        \n",
    "        # Redondear las columnas numéricas a 3 dígitos si existen\n",
    "        numeric_columns = ['Rank', 'Score', 'GDP per capita', 'Family', \n",
    "                           'Health (Life Expectancy)', 'Freedom', \n",
    "                           'Perceptions of corruption', 'Generosity']\n",
    "        for col in numeric_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(lambda x: round(x, 3) if isinstance(x, (int, float)) else x)\n",
    "        \n",
    "        # Renombrar las columnas para incluir el año\n",
    "        df = df.rename(columns={col: f\"{col} ({year})\" for col in df.columns if col != 'Country'})\n",
    "        \n",
    "        # Agregar el dataframe a la lista\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenar todos los dataframes por columnas\n",
    "consolidated_df = pd.concat(dataframes, axis=1)\n",
    "\n",
    "# Eliminar columnas duplicadas de 'Country'\n",
    "consolidated_df = consolidated_df.loc[:,~consolidated_df.columns.duplicated()]\n",
    "\n",
    "# Redondear las columnas numéricas a 3 dígitos en el dataframe consolidado si existen\n",
    "for col in consolidated_df.columns:\n",
    "    if any(numeric_col in col for numeric_col in numeric_columns):\n",
    "        consolidated_df[col] = consolidated_df[col].apply(lambda x: round(x, 3) if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# Ordenar el DataFrame combinado por el nombre de la columna \"Country\"\n",
    "consolidated_df.sort_values(by=['Country'], inplace=True)\n",
    "\n",
    "# Guardar el dataframe consolidado en un nuevo archivo CSV\n",
    "consolidated_df.to_csv('consolidado_happiness_v2.csv', index=False)\n",
    "\n",
    "print(\"Consolidación completa. Los datos consolidados se han guardado en consolidado_happiness_v2.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidación completa. Los datos consolidados se han guardado en consolidado_happiness_v2.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define la ruta de la carpeta y el archivo JSON\n",
    "folder_path = 'Datos/Happiness'\n",
    "json_path = 'Project_countries.json'\n",
    "\n",
    "# Define los mapeos de columnas\n",
    "column_mappings = {\n",
    "    'Country': ['Country', 'Country or region','Country name'],\n",
    "    'Rank': ['Happiness Rank', 'Overall rank', 'Happiness.Rank','Rank'],\n",
    "    'Score': ['Happiness Score', 'Score', 'Happiness.Score','Ladder score','Happiness score'],\n",
    "    'GDP per capita': ['Economy (GDP per Capita)', 'Economy..GDP.per.Capita.', 'GDP per capita','Logged GDP per capita','Explained by: GDP per capita'],\n",
    "    'Family': ['Family', 'Social support','Explained by: Social support'],\n",
    "    'Health (Life Expectancy)': ['Health (Life Expectancy)', 'Health..Life.Expectancy.', 'Healthy life expectancy','Explained by: Healthy life expectancy'],\n",
    "    'Freedom': ['Freedom', 'Freedom to make life choices','Explained by: Freedom to make life choices'],\n",
    "    'Perceptions of corruption': ['Trust (Government Corruption)', 'Trust..Government.Corruption.', 'Perceptions of corruption','Explained by: Perceptions of corruption'],\n",
    "    'Generosity': ['Generosity','Explained by: Generosity']\n",
    "}\n",
    "\n",
    "# Crear un diccionario inverso para los nombres alternativos\n",
    "alternate_names_to_official = {}\n",
    "with open(json_path, 'r', encoding='utf-8') as file:\n",
    "    project_countries = json.load(file)\n",
    "    for country, info in project_countries.items():\n",
    "        for alt_name in info.get('AlternateNames', []):\n",
    "            alternate_names_to_official[alt_name] = country\n",
    "\n",
    "# Función para estandarizar los nombres de las columnas y eliminar las no deseadas\n",
    "def standardize_columns(df):\n",
    "    standardized_columns = {}\n",
    "    for standard_col, possible_cols in column_mappings.items():\n",
    "        for col in possible_cols:\n",
    "            if col in df.columns:\n",
    "                standardized_columns[col] = standard_col\n",
    "                break\n",
    "    df = df.rename(columns=standardized_columns)\n",
    "    # Eliminar columnas que no están en los mapeos\n",
    "    columns_to_keep = list(standardized_columns.values())\n",
    "    df = df[columns_to_keep]\n",
    "    return df\n",
    "\n",
    "# Lista para almacenar los dataframes\n",
    "dataframes = []\n",
    "\n",
    "# DataFrame consolidado inicial\n",
    "consolidated_df = pd.DataFrame()\n",
    "\n",
    "# Iterar sobre los archivos en la carpeta\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extraer el año del nombre del archivo\n",
    "        year = int(''.join(filter(str.isdigit, filename)))\n",
    "        \n",
    "        # Leer el archivo CSV\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Eliminar filas vacías\n",
    "        df.dropna(how='all', inplace=True)\n",
    "        \n",
    "        # Estandarizar las columnas y eliminar las no deseadas\n",
    "        df = standardize_columns(df)\n",
    "        \n",
    "        # Asegurarse de que la columna Rank sea un entero\n",
    "        if 'Rank' in df.columns:\n",
    "            df['Rank'] = df['Rank'].astype(int)\n",
    "        else:\n",
    "            df['Rank'] = range(1, len(df) + 1)\n",
    "        \n",
    "        # Asegurarse de que los valores de 'Country' sean cadenas y manejar valores nulos\n",
    "        df['Country'] = df['Country'].astype(str).fillna('')\n",
    "        \n",
    "        # Reemplazar nombres alternativos por nombres oficiales\n",
    "        df['Country'] = df['Country'].apply(lambda x: alternate_names_to_official.get(x, x))\n",
    "        \n",
    "        # Filtrar las filas basadas en el archivo JSON\n",
    "        df = df[df['Country'].isin(project_countries)]\n",
    "        \n",
    "        # Redondear las columnas numéricas a 3 dígitos si existen\n",
    "        numeric_columns = ['Rank', 'Score', 'GDP per capita', 'Family', \n",
    "                           'Health (Life Expectancy)', 'Freedom', \n",
    "                           'Perceptions of corruption', 'Generosity']\n",
    "        for col in numeric_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(lambda x: round(x, 3) if isinstance(x, (int, float)) else x)\n",
    "        \n",
    "        # Renombrar las columnas para incluir el año\n",
    "        df = df.rename(columns={col: f\"{col} ({year})\" for col in df.columns if col != 'Country'})\n",
    "        \n",
    "        # Si el DataFrame consolidado está vacío, inicializarlo con el primer DataFrame\n",
    "        if consolidated_df.empty:\n",
    "            consolidated_df = df.set_index('Country')\n",
    "        else:\n",
    "            # Alinear los datos del nuevo DataFrame con el DataFrame consolidado\n",
    "            df = df.set_index('Country')\n",
    "            consolidated_df = consolidated_df.join(df, how='outer')\n",
    "        \n",
    "# Ordenar el DataFrame combinado por el nombre de la columna \"Country\"\n",
    "consolidated_df.sort_values(by=['Country'], inplace=True)\n",
    "\n",
    "# Guardar el dataframe consolidado en un nuevo archivo CSV\n",
    "consolidated_df.to_csv('consolidado_happiness_v2.csv')\n",
    "\n",
    "print(\"Consolidación completa. Los datos consolidados se han guardado en consolidado_happiness_v2.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidación completa. Los datos consolidados se han guardado en consolidado_happiness_v2.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define la ruta de la carpeta y el archivo JSON\n",
    "folder_path = 'Datos/Happiness'\n",
    "json_path = 'Project_countries.json'\n",
    "\n",
    "# Define los mapeos de columnas\n",
    "column_mappings = {\n",
    "    'Country': ['Country', 'Country or region','Country name'],\n",
    "    'Rank': ['Happiness Rank', 'Overall rank', 'Happiness.Rank','Rank'],\n",
    "    'Score': ['Happiness Score', 'Score', 'Happiness.Score','Ladder score','Happiness score'],\n",
    "    'GDP per capita': ['Economy (GDP per Capita)', 'Economy..GDP.per.Capita.', 'GDP per capita','Logged GDP per capita','Explained by: GDP per capita'],\n",
    "    'Family': ['Family', 'Social support','Explained by: Social support'],\n",
    "    'Health (Life Expectancy)': ['Health (Life Expectancy)', 'Health..Life.Expectancy.', 'Healthy life expectancy','Explained by: Healthy life expectancy'],\n",
    "    'Freedom': ['Freedom', 'Freedom to make life choices','Explained by: Freedom to make life choices'],\n",
    "    'Perceptions of corruption': ['Trust (Government Corruption)', 'Trust..Government.Corruption.', 'Perceptions of corruption','Explained by: Perceptions of corruption'],\n",
    "    'Generosity': ['Generosity','Explained by: Generosity']\n",
    "}\n",
    "\n",
    "# Crear un diccionario inverso para los nombres alternativos\n",
    "alternate_names_to_official = {}\n",
    "with open(json_path, 'r', encoding='utf-8') as file:\n",
    "    project_countries = json.load(file)\n",
    "    for country, info in project_countries.items():\n",
    "        for alt_name in info.get('AlternateNames', []):\n",
    "            alternate_names_to_official[alt_name] = country\n",
    "\n",
    "# Función para estandarizar los nombres de las columnas y eliminar las no deseadas\n",
    "def standardize_columns(df):\n",
    "    standardized_columns = {}\n",
    "    for standard_col, possible_cols in column_mappings.items():\n",
    "        for col in possible_cols:\n",
    "            if col in df.columns:\n",
    "                standardized_columns[col] = standard_col\n",
    "                break\n",
    "    df = df.rename(columns=standardized_columns)\n",
    "    # Eliminar columnas que no están en los mapeos\n",
    "    columns_to_keep = list(standardized_columns.values())\n",
    "    df = df[columns_to_keep]\n",
    "    return df\n",
    "\n",
    "# Lista para almacenar los dataframes\n",
    "dataframes = []\n",
    "\n",
    "# DataFrame consolidado inicial\n",
    "consolidated_df = pd.DataFrame()\n",
    "\n",
    "# Iterar sobre los archivos en la carpeta\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.startswith('Happiness') and filename.endswith('.csv'):\n",
    "        # Extraer el año del nombre del archivo\n",
    "        year = int(''.join(filter(str.isdigit, filename)))\n",
    "        \n",
    "        # Leer el archivo CSV\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Eliminar filas vacías\n",
    "        df.dropna(how='all', inplace=True)\n",
    "        \n",
    "        # Estandarizar las columnas y eliminar las no deseadas\n",
    "        df = standardize_columns(df)\n",
    "        \n",
    "        # Asegurarse de que la columna Rank sea un entero\n",
    "        if 'Rank' in df.columns:\n",
    "            df['Rank'] = df['Rank'].astype(int)\n",
    "        else:\n",
    "            df['Rank'] = range(1, len(df) + 1)\n",
    "        \n",
    "        # Asegurarse de que los valores de 'Country' sean cadenas y manejar valores nulos\n",
    "        df['Country'] = df['Country'].astype(str).fillna('')\n",
    "        \n",
    "        # Reemplazar nombres alternativos por nombres oficiales\n",
    "        df['Country'] = df['Country'].apply(lambda x: alternate_names_to_official.get(x, x))\n",
    "        \n",
    "        # Filtrar las filas basadas en el archivo JSON\n",
    "        df = df[df['Country'].isin(project_countries)]\n",
    "        \n",
    "        # Redondear las columnas numéricas a 3 dígitos si existen\n",
    "        numeric_columns = ['Rank', 'Score', 'GDP per capita', 'Family', \n",
    "                           'Health (Life Expectancy)', 'Freedom', \n",
    "                           'Perceptions of corruption', 'Generosity']\n",
    "        for col in numeric_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(lambda x: round(x, 3) if isinstance(x, (int, float)) else x)\n",
    "        \n",
    "        # Renombrar las columnas para incluir el año\n",
    "        df = df.rename(columns={col: f\"{col} ({year})\" for col in df.columns if col != 'Country'})\n",
    "        \n",
    "        # Si el DataFrame consolidado está vacío, inicializarlo con el primer DataFrame\n",
    "        if consolidated_df.empty:\n",
    "            consolidated_df = df.set_index('Country')\n",
    "        else:\n",
    "            # Alinear los datos del nuevo DataFrame con el DataFrame consolidado\n",
    "            df = df.set_index('Country')\n",
    "            consolidated_df = consolidated_df.join(df, how='outer')\n",
    "        \n",
    "# Ordenar el DataFrame combinado por el nombre de la columna \"Country\"\n",
    "consolidated_df.sort_values(by=['Country'], inplace=True)\n",
    "\n",
    "# Guardar el dataframe consolidado en un nuevo archivo CSV\n",
    "consolidated_df.to_csv('consolidado_happiness_v2.csv')\n",
    "\n",
    "print(\"Consolidación completa. Los datos consolidados se han guardado en consolidado_happiness_v2.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio actual: c:\\Users\\ProjectSupport\\Documents\\David\\Cursos\\Master Data Science\\Proyecto\n"
     ]
    }
   ],
   "source": [
    "# Verificar el directorio actual de trabajo\n",
    "current_directory = os.getcwd()\n",
    "print(f\"Directorio actual: {current_directory}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
